{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho 01\n",
    "\n",
    "Comparativo entre técnicas de machine learning e deep learning para uma tarefa de classificação no dataset de câncer de mama do scikit-learn: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dos dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = datasets.load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "\n",
    "normalizador = StandardScaler()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.09706398, -2.07333501,  1.26993369, ...,  2.29607613,\n",
       "         2.75062224,  1.93701461],\n",
       "       [ 1.82982061, -0.35363241,  1.68595471, ...,  1.0870843 ,\n",
       "        -0.24388967,  0.28118999],\n",
       "       [ 1.57988811,  0.45618695,  1.56650313, ...,  1.95500035,\n",
       "         1.152255  ,  0.20139121],\n",
       "       ...,\n",
       "       [ 0.70228425,  2.0455738 ,  0.67267578, ...,  0.41406869,\n",
       "        -1.10454895, -0.31840916],\n",
       "       [ 1.83834103,  2.33645719,  1.98252415, ...,  2.28998549,\n",
       "         1.91908301,  2.21963528],\n",
       "       [-1.80840125,  1.22179204, -1.81438851, ..., -1.74506282,\n",
       "        -0.04813821, -0.75120669]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = normalizador.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação de treino e teste\n",
    "\n",
    "São separados 20% das observações do dataset como dados de teste. Os dados são separados de maneira a manter a proporção presente do target do dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify= y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dos modelos e definição dos hiperparâmetros que serão ajustados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# !conda install -c conda-forge xgboost\n",
    "import xgboost as xgb\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "\n",
    "dict_algoritmos = {'logistic_regression': LogisticRegression(),\n",
    "                   'decision_tree'        : DecisionTreeClassifier(),\n",
    "                   'xgboost'              : xgb.XGBClassifier()}\n",
    "\n",
    "dict_param_grid_algoritmos = {'logistic_regression' : {'penalty'          : ['l1'], \n",
    "                                                       'C'                : uniform(0.01, 100.0), \n",
    "                                                       'fit_intercept'    : [False, True],\n",
    "                                                       'max_iter'         : randint(100,3000),\n",
    "                                                       'solver'           : ['liblinear', 'saga']},\n",
    "                             'decision_tree'        : {'splitter'         : [\"best\", \"random\"],\n",
    "                                                       'max_depth'        : randint(3,20) ,\n",
    "                                                       'min_samples_split': randint(1,7),\n",
    "                                                       'min_samples_leaf' : randint(1, 10)},\n",
    "                             'xgboost'              : {'learning_rate'    : uniform(0.05, 0.3),\n",
    "                                                       'max_depth'        : randint(3,20) ,\n",
    "                                                       'min_child_weight' : randint(1,7),\n",
    "                                                       'gamma'            : uniform(0.0, 1.0),\n",
    "                                                       'colsample_bytree' : uniform(0.1, 1.0)}}\n",
    "\n",
    "# dicionário para armazenamento dos modelos treinados\n",
    "\n",
    "dict_modelos_treinados = {}\n",
    "\n",
    "# parâmetros da busca randomizada: \n",
    "\n",
    "# o número de folds igual a 4 implica em 60% do dataset para treino, 20% para validação e 20% para teste\n",
    "num_folds = 4 \n",
    "# número de iterações para a busca randomizada\n",
    "num_iter = 500\n",
    "# objeto que realiza os aplits de forma estratificada\n",
    "cv = StratifiedKFold(n_splits= num_folds, shuffle= True)\n",
    "\n",
    "args_random_search = {'cv'                 : cv, \n",
    "                      'scoring'            :'f1_macro', \n",
    "                      'n_jobs'             : -1,\n",
    "                      'verbose'            : 10,\n",
    "                      'n_iter'             : num_iter}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparametrização e treinamento do modelo linear\n",
    "algoritmo: regressão logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 500 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1867s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 134 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 198 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1620s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 263 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=-1)]: Done 326 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done 372 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done 397 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=-1)]: Done 422 tasks      | elapsed:   43.5s\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=-1)]: Done 476 tasks      | elapsed:   53.3s\n",
      "[Parallel(n_jobs=-1)]: Done 505 tasks      | elapsed:   57.1s\n",
      "[Parallel(n_jobs=-1)]: Done 534 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1868s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1289s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3208s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 664 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 697 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 730 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 765 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1988s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 800 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1999s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1307s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 890 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 930 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 969 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1049 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1090 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1133 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1176 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1221 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1266 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1925s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 1338 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0804s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1986s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (3.1195s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 1404 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1453 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1502 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1553 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1604 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1657 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1710 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1936s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1919s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.6107s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 1824 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1888 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1945 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  3.8min finished\n",
      "/home/eduardodut/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "algoritmo = 'logistic_regression'\n",
    "\n",
    "args_random_search['estimator']           =  dict_algoritmos[algoritmo]\n",
    "args_random_search['param_distributions'] = dict_param_grid_algoritmos[algoritmo]\n",
    "                      \n",
    "random_search = RandomizedSearchCV(**args_random_search)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "dict_modelos_treinados[algoritmo] = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=61.045102049841816, max_iter=233,\n",
       "                                    penalty='l1', solver='saga'))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_modelos_treinados[algoritmo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparametrização e treinamento do modelo de árvore de decisão\n",
    "algoritmo: Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 500 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0405s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1335s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1251s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 584 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 704 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 824 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1096 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1248 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1400 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1568 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1736 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1920 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1992 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:   12.0s finished\n"
     ]
    }
   ],
   "source": [
    "algoritmo = 'decision_tree'\n",
    "\n",
    "args_random_search['estimator']           =  dict_algoritmos[algoritmo]\n",
    "args_random_search['param_distributions'] = dict_param_grid_algoritmos[algoritmo]\n",
    "                      \n",
    "random_search = RandomizedSearchCV(**args_random_search)\n",
    "\n",
    "random_search.fit( X_train, y_train)\n",
    "\n",
    "dict_modelos_treinados[algoritmo] = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=8, min_samples_leaf=4, splitter='random')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_modelos_treinados[algoritmo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparametrização e treinamento do modelo ensemble\n",
    "algoritmo: xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 500 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0854s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 266 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 460 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 506 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 552 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 602 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 652 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 760 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 818 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done 938 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1066 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1132 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1272 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1346 tasks      | elapsed:   34.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1420 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1498 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:   40.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1658 tasks      | elapsed:   42.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1740 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1826 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1912 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:   51.0s finished\n"
     ]
    }
   ],
   "source": [
    "algoritmo = 'xgboost'\n",
    "\n",
    "args_random_search['estimator']           =  dict_algoritmos[algoritmo]\n",
    "args_random_search['param_distributions'] = dict_param_grid_algoritmos[algoritmo]\n",
    "                      \n",
    "random_search = RandomizedSearchCV(**args_random_search)\n",
    "\n",
    "random_search.fit( X_train, y_train)\n",
    "\n",
    "dict_modelos_treinados[algoritmo] = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.23774179085114036,\n",
       "              gamma=0.43305308610611326, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.1794674255230308,\n",
       "              max_delta_step=0, max_depth=19, min_child_weight=6, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_modelos_treinados[algoritmo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparametrização e treinamento do modelo de rede neural\n",
    "https://www.sicara.ai/blog/hyperparameter-tuning-keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import da biblioteca e verificação de disponibilidade de gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "# !conda install -c conda-forge keras-tuner\n",
    "import kerastuner as hp\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", \n",
    "      len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construção do modelo para busca de hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from kerastuner import HyperParameters as hp\n",
    "\n",
    "def get_model(hp):\n",
    "    \n",
    "    \n",
    "    new_model = Sequential()\n",
    "\n",
    "    new_model.add(Dense(units = hp.Int('n_units_l1',\n",
    "                                min_value=32,\n",
    "                                max_value=512,\n",
    "                                step=32,\n",
    "                                default=128),\n",
    "                   activation = hp.Choice('dense_activation_l1',\n",
    "                                          values=['relu', 'tanh', 'sigmoid'],\n",
    "                                          default='relu')))\n",
    "           \n",
    "    new_model.add(Dense(units = hp.Int('n_units_l2',\n",
    "                                min_value=8,\n",
    "                                max_value=128,\n",
    "                                step=16,\n",
    "                                default=64),\n",
    "                   activation = hp.Choice('dense_activation_l2',\n",
    "                                          values=['relu', 'tanh', 'sigmoid'],\n",
    "                                          default='relu')))    \n",
    "   \n",
    "    new_model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    \n",
    "    new_model.compile(loss='binary_crossentropy', \n",
    "                      optimizer= 'adam', \n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    return new_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### instanciação do objeto de busca de hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    get_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### busca de hiperparâmetros com validation split de 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             epochs=40,\n",
    "             validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Results in ./untitled_project</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Objective(name='val_accuracy', direction='max')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: a948d75bf91652234e8fee5f1165819c</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.9890109896659851</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-unit: 104</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 7399890a7f67ff3c65049a4f1ceef874</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.9890109896659851</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-unit: 72</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 113930d5ebac9489e596225211250b3b</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.9890109896659851</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-unit: 88</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 37835d25337da1bfc4f4ac0f59c1d63f</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.9890109896659851</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-unit: 88</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 1a127399c88c9f6df4041335076c6d5f</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.9890109896659851</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-unit: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units: 320</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 1c711c7d387880b6a7cd45e5b21f1b0a</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.9853479862213135</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-unit: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units: 384</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: d4b70c79dfd766c146aa909f898dc754</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.9853479862213135</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-unit: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units: 288</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 02a9bb318117a8310d388bc7837f05fc</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.9853479862213135</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation: relu</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-unit: 88</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units: 416</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 4b35f69750a6c3bc090dc935ee53bc91</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.9853479862213135</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation: tanh</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-unit: 40</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units: 416</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 42eab1d3a37f5590c058c3c059bc5d22</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.9816849827766418</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_activation: sigmoid</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-unit: 56</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-units: 352</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construção do modelo com os melhores parâmetros encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  9920      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  102720    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  321       \n",
      "=================================================================\n",
      "Total params: 112,961\n",
      "Trainable params: 112,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.build(input_shape = (1,X.shape[1]))\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 288)               8928      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 289       \n",
      "=================================================================\n",
      "Total params: 9,217\n",
      "Trainable params: 9,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units = 320,\n",
    "                    input_dim = X.shape[1],\n",
    "                    activation = 'relu'))\n",
    "\n",
    "# model.add(Dense(units = 416,\n",
    "#                     activation = 'relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer= 'adam', \n",
    "                  metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### treinamento do modelo parametrizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.9802e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5652e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.6102e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3191e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2689e-08 - accuracy: 0.83 - 1s 14ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 2/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 8.2530e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.8054e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3544e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1951e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2153e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 3/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.7945e-08 - accuracy: 0.76 - ETA: 0s - loss: 7.9996e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.6161e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.6764e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 4/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 1s - loss: 9.6858e-08 - accuracy: 0.93 - ETA: 0s - loss: 7.3264e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.9737e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2732e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 5/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.5860e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1369e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3954e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3574e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 6/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 1s - loss: 8.4440e-08 - accuracy: 0.87 - ETA: 1s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 1s - loss: 7.2022e-08 - accuracy: 0.89 - ETA: 0s - loss: 7.1313e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2562e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2314e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3761e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3052e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3796e-08 - accuracy: 0.83 - 1s 19ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 7/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.1095e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.5565e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.0893e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1438e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2427e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 1s 13ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 8/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 5.7742e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.9921e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.0123e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.0442e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.9881e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.0035e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.83 - 1s 13ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 9/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.5860e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.9211e-08 - accuracy: 0.80 - ETA: 0s - loss: 8.0237e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.7135e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4888e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4167e-08 - accuracy: 0.82 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 10/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1067e-08 - accuracy: 0.80 - ETA: 0s - loss: 6.8675e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1622e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4133e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 11/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.80 - ETA: 0s - loss: 6.9247e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1667e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1401e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.0660e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1194e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2812e-08 - accuracy: 0.82 - 1s 13ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 12/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.9802e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.9473e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5215e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5610e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3629e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4114e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4878e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 1s 14ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 13/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.62 - ETA: 0s - loss: 6.1095e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.5400e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.6310e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.7353e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.9699e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.8711e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2080e-08 - accuracy: 0.82 - 1s 15ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 14/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.88 - ETA: 0s - loss: 6.9800e-08 - accuracy: 0.86 - ETA: 0s - loss: 6.9348e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.2545e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 15/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.4572e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.0367e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3314e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2080e-08 - accuracy: 0.84 - 1s 14ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 16/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 8.2784e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.7945e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4040e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3298e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 17/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 1.4901e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.7987e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2298e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1712e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1761e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 18/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5821e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3844e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 19/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 1s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.9765e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.9473e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.6890e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3478e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3264e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 1s 13ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 20/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.0930e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4944e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 21/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.8570e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2964e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4054e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3264e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3298e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 1s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 22/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 1.00 - ETA: 0s - loss: 7.5860e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.6368e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5860e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2689e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 23/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2213e-08 - accuracy: 0.76 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.3761e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3779e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 24/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.50 - ETA: 0s - loss: 7.9924e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.8427e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4025e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2732e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 25/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 8.2530e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.7643e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3210e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3388e-08 - accuracy: 0.83 - 0s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 26/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.9921e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3742e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 27/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.0442e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.5290e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.4920e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4124e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 28/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.68 - ETA: 0s - loss: 8.4440e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.8763e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.5020e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2689e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 29/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1313e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3210e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3885e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.5499e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4133e-08 - accuracy: 0.84 - 1s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 30/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 1s - loss: 6.7055e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.7486e-08 - accuracy: 0.95 - ETA: 0s - loss: 7.5996e-08 - accuracy: 0.90 - ETA: 0s - loss: 7.6859e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.6161e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3678e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3761e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4142e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4159e-08 - accuracy: 0.83 - 1s 16ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 31/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.7552e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.0494e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.0643e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1423e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2595e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 32/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1067e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1284e-08 - accuracy: 0.84 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 33/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.8775e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.1937e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.3109e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3654e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 34/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 1.00 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5467e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 35/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.5996e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2718e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2909e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4068e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.83 - 1s 14ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 36/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.8120e-08 - accuracy: 0.80 - ETA: 0s - loss: 6.8918e-08 - accuracy: 0.80 - ETA: 0s - loss: 6.7800e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3466e-08 - accuracy: 0.84 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 37/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.50 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.1369e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 38/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.0478e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 39/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.86 - ETA: 0s - loss: 6.9800e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1797e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1246e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2153e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3813e-08 - accuracy: 0.83 - 1s 12ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 40/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.6161e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.7486e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.6161e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.6161e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 41/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2474e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2786e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2314e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 42/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.50 - ETA: 1s - loss: 6.7055e-08 - accuracy: 0.68 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3678e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.0442e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3052e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 1s 14ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 43/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.1733e-08 - accuracy: 0.91 - ETA: 0s - loss: 7.0248e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3210e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3629e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4092e-08 - accuracy: 0.81 - 0s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 44/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.0160e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.9699e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 45/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1313e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.0958e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2595e-08 - accuracy: 0.82 - 1s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 46/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.1921e-07 - accuracy: 1.00 - ETA: 0s - loss: 8.3447e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.8976e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.7610e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5860e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4124e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 47/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.79 - ETA: 0s - loss: 6.8711e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2718e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3191e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1734e-08 - accuracy: 0.82 - 0s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 48/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.2519e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.6368e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5437e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5334e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3466e-08 - accuracy: 0.82 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 49/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 1.00 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5860e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2474e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3109e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3264e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2773e-08 - accuracy: 0.84 - 1s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 50/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.4572e-08 - accuracy: 0.89 - ETA: 0s - loss: 6.2585e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.9184e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2786e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4909e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 51/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1194e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.7883e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1141e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3466e-08 - accuracy: 0.83 - 0s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 52/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 2s - loss: 6.7055e-08 - accuracy: 0.81 - ETA: 2s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 2s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 2s - loss: 6.7055e-08 - accuracy: 0.81 - ETA: 3s - loss: 7.0248e-08 - accuracy: 0.80 - ETA: 3s - loss: 7.2643e-08 - accuracy: 0.82 - ETA: 2s - loss: 7.3151e-08 - accuracy: 0.82 - ETA: 1s - loss: 7.1712e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5860e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4888e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5545e-08 - accuracy: 0.83 - 1s 25ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 53/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.8570e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4957e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 54/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.9921e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.0367e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3087e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4009e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4133e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 1s 13ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 55/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.9802e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.6225e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5382e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2732e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 56/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 0s - loss: 8.7917e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.6161e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3544e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5714e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4888e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3415e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2812e-08 - accuracy: 0.83 - 1s 14ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 57/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.5079e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4054e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3120e-08 - accuracy: 0.84 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 58/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.9473e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2937e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2786e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3654e-08 - accuracy: 0.84 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 59/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.8297e-08 - accuracy: 0.86 - ETA: 0s - loss: 6.6227e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.8120e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.9323e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.0660e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2153e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2325e-08 - accuracy: 0.82 - 1s 12ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 60/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 0s - loss: 7.8763e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3574e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.3858e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.6047e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 61/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1000e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3210e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3629e-08 - accuracy: 0.81 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 62/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.5570e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1401e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3120e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 63/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.8120e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.7312e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.9685e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1898e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 64/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 0s - loss: 7.1067e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.3087e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.3974e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.81 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 65/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.0315e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 66/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.6989e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4986e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3742e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3796e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 67/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.7733e-08 - accuracy: 0.79 - ETA: 0s - loss: 6.7800e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4957e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.5652e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 68/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 1.00 - ETA: 0s - loss: 7.7699e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3910e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2314e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 69/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.7817e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.0584e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4068e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 70/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.89 - ETA: 0s - loss: 7.1746e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2753e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3120e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 71/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.1000e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.2102e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 72/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 0s - loss: 7.6989e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5334e-08 - accuracy: 0.82 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 73/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.4075e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.1712e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3992e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.9397e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1734e-08 - accuracy: 0.83 - 1s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 74/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.62 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5698e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2492e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 75/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 9.1270e-08 - accuracy: 0.78 - ETA: 0s - loss: 8.1956e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3574e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.7097e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2248e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2977e-08 - accuracy: 0.83 - 1s 12ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 76/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 6.6227e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1914e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 77/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.9247e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2178e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4114e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2474e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 78/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.3264e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.1194e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3191e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3779e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 79/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.6493e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3064e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 80/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.9087e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.3478e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3574e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3700e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 81/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 1.00 - ETA: 0s - loss: 7.6989e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.3974e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.4068e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.1898e-08 - accuracy: 0.85 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 82/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 0s - loss: 8.0715e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.6989e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.6161e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3828e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 83/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.4901e-08 - accuracy: 1.00 - ETA: 0s - loss: 5.4638e-08 - accuracy: 0.93 - ETA: 0s - loss: 7.0958e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.4971e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4068e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 84/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2519e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3402e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4092e-08 - accuracy: 0.84 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 85/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.4572e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1194e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2102e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.4167e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 86/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.8763e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2298e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2436e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2271e-08 - accuracy: 0.84 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 87/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0532e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3120e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 88/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1914e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1284e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 89/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 8.1383e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.8889e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 90/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.9849e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.9348e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2450e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.84 - 1s 15ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 91/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.4572e-08 - accuracy: 0.89 - ETA: 0s - loss: 7.0584e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3064e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4103e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3828e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 92/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 0s - loss: 8.1383e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.6890e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3603e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 1s 15ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 93/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.5565e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.5193e-08 - accuracy: 0.89 - ETA: 0s - loss: 6.4572e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.3858e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.3064e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2213e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 1s 15ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 94/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.9802e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.8120e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.5570e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.5860e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 95/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5499e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.2271e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.2718e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1345e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2595e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 1s 14ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 96/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.5565e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.84 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 97/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.68 - ETA: 0s - loss: 8.0466e-08 - accuracy: 0.78 - ETA: 0s - loss: 8.2349e-08 - accuracy: 0.84 - ETA: 0s - loss: 8.0715e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.7589e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4898e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4861e-08 - accuracy: 0.82 - 1s 12ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 98/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 8.1956e-08 - accuracy: 0.82 - ETA: 0s - loss: 8.2888e-08 - accuracy: 0.83 - ETA: 0s - loss: 8.1129e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.9473e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5038e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2700e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3678e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4124e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 1s 16ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 99/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.8711e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3742e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 100/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.6989e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.8351e-08 - accuracy: 0.84 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 101/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.3490e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 102/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.3264e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3910e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3544e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1831e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 103/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.5193e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.2798e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.8120e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.2964e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2595e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 104/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 8.0466e-08 - accuracy: 0.90 - ETA: 0s - loss: 8.3819e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.6538e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 105/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 1.00 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4920e-08 - accuracy: 0.81 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 106/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.9802e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.7883e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.2298e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 107/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0035e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3229e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3828e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 108/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 8.2784e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.7486e-08 - accuracy: 0.90 - ETA: 0s - loss: 7.6538e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5860e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4159e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 109/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.9211e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3992e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 110/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.50 - ETA: 0s - loss: 6.9921e-08 - accuracy: 0.80 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3229e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4114e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 111/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.1313e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5652e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2753e-08 - accuracy: 0.81 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 112/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.2153e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3954e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 113/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.5652e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.6368e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5698e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5570e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3329e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 1s 14ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 114/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 0s - loss: 7.6989e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5948e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3761e-08 - accuracy: 0.84 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 115/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2909e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 116/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3603e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4861e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 117/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.1067e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3761e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 118/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.9473e-08 - accuracy: 0.76 - ETA: 0s - loss: 7.7699e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5802e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2689e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 0s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 119/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.7945e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2102e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4151e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 120/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.50 - ETA: 0s - loss: 8.0237e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.2562e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1141e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1898e-08 - accuracy: 0.84 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 121/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.6368e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4040e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4159e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 122/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2545e-08 - accuracy: 0.82 - 0s 4ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 123/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.5652e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1746e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3813e-08 - accuracy: 0.82 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 124/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 0s - loss: 7.3264e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3933e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 125/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.90 - ETA: 0s - loss: 7.2474e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2753e-08 - accuracy: 0.86 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 126/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0248e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.6161e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.3052e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 127/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.9802e-08 - accuracy: 0.50 - ETA: 0s - loss: 7.6635e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.8297e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.6538e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.6561e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.5682e-08 - accuracy: 0.81 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 128/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 0s - loss: 7.5437e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3402e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2089e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 129/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.9016e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2436e-08 - accuracy: 0.82 - 0s 4ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 130/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.8120e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.6798e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3191e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.3330e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.0893e-08 - accuracy: 0.84 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 132/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 8.1956e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.7892e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 133/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.4986e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3813e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 134/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.3678e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3402e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3191e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2595e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 135/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.6161e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 136/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.1369e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0561e-08 - accuracy: 0.82 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 137/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.5860e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3779e-08 - accuracy: 0.83 - 0s 4ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 138/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.7817e-08 - accuracy: 0.90 - ETA: 0s - loss: 7.5290e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3544e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3779e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 139/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.5437e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.6989e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4869e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 140/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.37 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.8918e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2753e-08 - accuracy: 0.84 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 141/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.8545e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.6368e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.85 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 142/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.5183e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.4898e-08 - accuracy: 0.84 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 143/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.9802e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.4310e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.0478e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 144/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.86 - ETA: 0s - loss: 6.9247e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1369e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1712e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.82 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 145/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.6741e-08 - accuracy: 0.76 - ETA: 0s - loss: 7.3402e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3298e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 146/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.8775e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.8829e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.0091e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.4092e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3828e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 147/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.5652e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.6989e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.6713e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3329e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 148/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.1797e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4888e-08 - accuracy: 0.83 - 0s 4ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 149/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.6713e-08 - accuracy: 0.89 - ETA: 0s - loss: 7.4944e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3813e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 150/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.6449e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.5783e-08 - accuracy: 0.84 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 151/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.9996e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5783e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 152/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 1.00 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.3910e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4080e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4151e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 153/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 8.1956e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.9828e-08 - accuracy: 0.83 - ETA: 0s - loss: 8.0466e-08 - accuracy: 0.83 - ETA: 0s - loss: 8.0025e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.5334e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.82 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.7883e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.1067e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5437e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3052e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 155/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.6989e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.8889e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.5802e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3954e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5357e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3466e-08 - accuracy: 0.82 - 1s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 156/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.5860e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.1667e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 157/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.8545e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.0123e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1845e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.0977e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 158/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.8570e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5334e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.0619e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2450e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1598e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 159/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 8.0715e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5154e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.3191e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3490e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 160/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.3478e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.0893e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 161/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.7745e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3742e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 162/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.1797e-08 - accuracy: 0.88 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.3052e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 163/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1000e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 164/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.8775e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.5652e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2977e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 165/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.50 - ETA: 0s - loss: 6.8370e-08 - accuracy: 0.77 - ETA: 0s - loss: 7.3992e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4103e-08 - accuracy: 0.84 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 166/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4068e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5199e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 167/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.8675e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2937e-08 - accuracy: 0.84 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 168/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.5251e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2812e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 169/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.3629e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.6117e-08 - accuracy: 0.83 - 0s 4ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 170/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 171/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 0s - loss: 6.9016e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1876e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 172/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.8545e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.89 - ETA: 0s - loss: 7.0619e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.1194e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 173/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.5596e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 174/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.8711e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 175/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 8.3447e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.6635e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.6429e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5290e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 176/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.7215e-08 - accuracy: 0.89 - ETA: 0s - loss: 7.5610e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3700e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 177/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.7486e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2545e-08 - accuracy: 0.82 - 0s 4ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 178/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.0584e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.1449e-08 - accuracy: 0.82 - 0s 4ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 179/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.9290e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.0584e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 180/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 2s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 2s - loss: 7.9473e-08 - accuracy: 0.87 - ETA: 1s - loss: 7.6635e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.8120e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2271e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.6225e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.8103e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.8450e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5545e-08 - accuracy: 0.83 - 1s 15ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 181/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 1.00 - ETA: 1s - loss: 8.1956e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.85 - ETA: 0s - loss: 8.1025e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.8082e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2803e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3120e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 1s 13ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 182/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 8.5682e-08 - accuracy: 0.87 - ETA: 0s - loss: 8.6427e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3264e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.2937e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3885e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2325e-08 - accuracy: 0.83 - 1s 14ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 183/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 1.00 - ETA: 0s - loss: 8.1956e-08 - accuracy: 0.76 - ETA: 0s - loss: 7.7817e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3974e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2595e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 1s 13ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 184/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.7486e-08 - accuracy: 0.80 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.9087e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.0909e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1029e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.1622e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.0584e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 1s 15ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 185/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 0s - loss: 7.8976e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.7892e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4971e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 186/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.50 - ETA: 0s - loss: 5.7121e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.4572e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.6617e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 187/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.73 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2562e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2753e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 188/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2153e-08 - accuracy: 0.84 - ETA: 0s - loss: 6.9141e-08 - accuracy: 0.84 - ETA: 0s - loss: 6.7587e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1438e-08 - accuracy: 0.83 - 1s 14ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 189/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.7300e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.6074e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.5860e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.6989e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.5020e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.4080e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2271e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2427e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2474e-08 - accuracy: 0.83 - 1s 19ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 190/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0248e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.5652e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2937e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3478e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2595e-08 - accuracy: 0.84 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 191/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1313e-08 - accuracy: 0.91 - ETA: 0s - loss: 7.0584e-08 - accuracy: 0.90 - ETA: 0s - loss: 6.8120e-08 - accuracy: 0.84 - ETA: 0s - loss: 6.9849e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 192/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.1194e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.3992e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3844e-08 - accuracy: 0.83 - 1s 12ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 193/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 0s - loss: 8.6923e-08 - accuracy: 0.77 - ETA: 0s - loss: 8.3021e-08 - accuracy: 0.76 - ETA: 0s - loss: 8.1025e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.7215e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.7610e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.8678e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.7589e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4114e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 1s 17ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 194/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.9091e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.7097e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4878e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3813e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 195/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1194e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.9162e-08 - accuracy: 0.84 - ETA: 0s - loss: 8.0337e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2595e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 196/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4080e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 197/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 1s - loss: 8.9407e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.2753e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.3314e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3064e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.4124e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 1s 17ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 198/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.9802e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.1067e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2595e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 199/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.0248e-08 - accuracy: 0.91 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.3264e-08 - accuracy: 0.84 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 200/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.9041e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5409e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4869e-08 - accuracy: 0.84 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 201/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.78 - ETA: 0s - loss: 6.8918e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4068e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 202/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.5698e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3191e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 203/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4092e-08 - accuracy: 0.84 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 204/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.6161e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5996e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.7817e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.6161e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 205/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3629e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 206/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.5437e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3574e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.3813e-08 - accuracy: 0.84 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 207/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.6559e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1423e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2080e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 208/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 209/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.6378e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.8120e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.3478e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3052e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 210/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3415e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 211/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.3669e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 212/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.0395e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3052e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 213/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.77 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.9990e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 214/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2519e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1761e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2135e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 215/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.3264e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.8410e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1687e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 216/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.2786e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3700e-08 - accuracy: 0.84 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 217/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 1.00 - ETA: 0s - loss: 8.4750e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.5948e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 218/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.9162e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.82 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 219/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.7643e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.6429e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3466e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 220/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.8775e-08 - accuracy: 0.79 - ETA: 0s - loss: 6.8201e-08 - accuracy: 0.80 - ETA: 0s - loss: 6.8636e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.0685e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 221/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 8.3447e-08 - accuracy: 0.95 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.90 - ETA: 0s - loss: 7.3954e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.5233e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 222/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.50 - ETA: 0s - loss: 7.3574e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3052e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 223/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.8120e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1153e-08 - accuracy: 0.82 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 224/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.5499e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.5058e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4080e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 225/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.6047e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4986e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5311e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 226/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.9184e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0248e-08 - accuracy: 0.86 - ETA: 0s - loss: 6.9673e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 227/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.5991e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.8918e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.8297e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.9800e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3954e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1284e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3087e-08 - accuracy: 0.83 - 1s 13ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 228/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 1.00 - ETA: 0s - loss: 8.4440e-08 - accuracy: 0.87 - ETA: 0s - loss: 8.2784e-08 - accuracy: 0.76 - ETA: 0s - loss: 7.5251e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.5860e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4151e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 229/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 8.2634e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3678e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.2773e-08 - accuracy: 0.84 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 230/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.6368e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.6161e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.6312e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.82 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 231/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1797e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.6368e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3858e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5382e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 232/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.5996e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3828e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3954e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4986e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3654e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4114e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4124e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3761e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 1s 16ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 233/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5748e-08 - accuracy: 0.89 - ETA: 0s - loss: 7.7817e-08 - accuracy: 0.89 - ETA: 0s - loss: 7.7075e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 1s 13ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.50 - ETA: 0s - loss: 8.3021e-08 - accuracy: 0.73 - ETA: 0s - loss: 7.9091e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.8427e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.8976e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.6890e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.6635e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.5948e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.5311e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 1s 15ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 235/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2937e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 236/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.62 - ETA: 0s - loss: 6.8120e-08 - accuracy: 0.89 - ETA: 0s - loss: 7.8889e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4124e-08 - accuracy: 0.81 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 237/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.0532e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.0442e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3742e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3490e-08 - accuracy: 0.82 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 238/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.7945e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.5748e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 239/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.9802e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.0367e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3603e-08 - accuracy: 0.82 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 240/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.88 - ETA: 0s - loss: 6.8775e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.84 - ETA: 0s - loss: 6.6617e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.8120e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.0494e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1141e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 1s 12ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 241/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.62 - ETA: 0s - loss: 6.4572e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.0123e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3264e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3954e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3478e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3264e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4124e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2427e-08 - accuracy: 0.83 - 1s 16ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 242/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.7733e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4151e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 243/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.7300e-08 - accuracy: 0.76 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2436e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3844e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 244/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.7486e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.1119e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2519e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4092e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1734e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 245/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.9473e-08 - accuracy: 0.76 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5058e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5003e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3700e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2595e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.83 - 1s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 246/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 1.00 - ETA: 0s - loss: 5.6624e-08 - accuracy: 0.88 - ETA: 0s - loss: 6.8545e-08 - accuracy: 0.86 - ETA: 0s - loss: 6.9348e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.8545e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.9990e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.0674e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 1s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 247/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 0s - loss: 7.9473e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3574e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 248/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.6798e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.6635e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.6368e-08 - accuracy: 0.85 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 249/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2753e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 250/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2213e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.2786e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4151e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 251/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.9802e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.7486e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.3109e-08 - accuracy: 0.82 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 252/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.62 - ETA: 0s - loss: 8.1279e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.5079e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 253/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.2753e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2689e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 254/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.0248e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.0584e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.0643e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1313e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.83 - 0s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 255/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1369e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3844e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 256/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.9828e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5038e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 257/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.1313e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1401e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3388e-08 - accuracy: 0.84 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 258/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3574e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.5533e-08 - accuracy: 0.80 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 259/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.2519e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1067e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 260/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.3629e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5860e-08 - accuracy: 0.84 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 261/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 0s - loss: 7.7300e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3574e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3796e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 262/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.7945e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.8054e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.8351e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 263/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.1712e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 264/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.50 - ETA: 0s - loss: 7.1313e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.7699e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5270e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3490e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 265/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.9802e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.5748e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.6449e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4151e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 266/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1313e-08 - accuracy: 0.73 - ETA: 0s - loss: 7.5996e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.3796e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 267/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.5821e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 268/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.6161e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 269/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.5652e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.7215e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1712e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4114e-08 - accuracy: 0.84 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 270/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.50 - ETA: 0s - loss: 6.8918e-08 - accuracy: 0.76 - ETA: 0s - loss: 6.8918e-08 - accuracy: 0.78 - ETA: 0s - loss: 6.9765e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.0091e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1369e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2080e-08 - accuracy: 0.83 - 1s 16ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 271/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.6161e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.8479e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.8082e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3264e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 272/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.6798e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2474e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.0333e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.83 - 1s 12ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 273/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 8.3447e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.5437e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.1313e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 274/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 0s - loss: 7.1194e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5925e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5102e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2689e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.9162e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3478e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4175e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 276/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.2798e-08 - accuracy: 0.91 - ETA: 0s - loss: 6.7312e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.2773e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 277/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.50 - ETA: 0s - loss: 7.1369e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.4040e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 278/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 8.1956e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.6161e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1687e-08 - accuracy: 0.84 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 279/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.2916e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 280/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.6227e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1712e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2812e-08 - accuracy: 0.84 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 281/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.9921e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1067e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.2753e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2803e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2436e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2895e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3388e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2773e-08 - accuracy: 0.83 - 1s 20ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 282/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.7486e-08 - accuracy: 0.90 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4957e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 283/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.9849e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2450e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2436e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 284/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1313e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3064e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 285/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4971e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 286/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 8.3021e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.5003e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3779e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 1s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 287/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.6368e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5334e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1746e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.1598e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 288/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.5499e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.0930e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3654e-08 - accuracy: 0.81 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 289/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.0395e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1898e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 290/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.3678e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2909e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4957e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4861e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 291/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 1.00 - ETA: 0s - loss: 7.6798e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 292/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.50 - ETA: 0s - loss: 7.5652e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1608e-08 - accuracy: 0.80 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 293/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.0846e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2519e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3052e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 294/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.8976e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5409e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2977e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 295/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.5565e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.80 - ETA: 0s - loss: 6.8711e-08 - accuracy: 0.80 - ETA: 0s - loss: 6.6731e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3264e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3844e-08 - accuracy: 0.83 - 0s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 296/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0035e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.0619e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2700e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 297/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 4.9671e-08 - accuracy: 0.79 - ETA: 0s - loss: 6.7552e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.0315e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 298/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.78 - ETA: 0s - loss: 6.8711e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1797e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2080e-08 - accuracy: 0.84 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 299/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.1797e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5821e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 300/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.1876e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.1667e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 301/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.80 - ETA: 0s - loss: 6.8545e-08 - accuracy: 0.80 - ETA: 0s - loss: 6.9765e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2248e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3844e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 302/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.1369e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1622e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3828e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 303/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1712e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2298e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1797e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4114e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3087e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 304/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.5023e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.7883e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1640e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3678e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 305/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.5570e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5311e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 306/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.5996e-08 - accuracy: 0.90 - ETA: 0s - loss: 7.6161e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5079e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3329e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 307/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 8.0466e-08 - accuracy: 0.77 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2786e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5290e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 308/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3415e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 309/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.5652e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.5996e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5020e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4909e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 310/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 1.00 - ETA: 0s - loss: 8.5486e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.6575e-08 - accuracy: 0.84 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 311/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.9473e-08 - accuracy: 0.79 - ETA: 0s - loss: 6.5565e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.8410e-08 - accuracy: 0.84 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4103e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4159e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 312/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.87 - ETA: 0s - loss: 8.2453e-08 - accuracy: 0.84 - ETA: 0s - loss: 8.0274e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4861e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 313/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.6559e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4054e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 314/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.7486e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.7486e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4080e-08 - accuracy: 0.82 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 315/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.4075e-08 - accuracy: 0.80 - ETA: 0s - loss: 6.6757e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1067e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 316/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.80 - ETA: 0s - loss: 8.0237e-08 - accuracy: 0.80 - ETA: 0s - loss: 8.5268e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.9924e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.8393e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5334e-08 - accuracy: 0.84 - 1s 13ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 317/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.4572e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.2474e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1423e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2089e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 318/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.0958e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 319/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.6368e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2519e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3678e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3779e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 320/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.3669e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.1667e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2964e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3329e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 321/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.6482e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.0035e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3974e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4025e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3761e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 322/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.6559e-08 - accuracy: 0.70 - ETA: 0s - loss: 6.5991e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.7628e-08 - accuracy: 0.77 - ETA: 0s - loss: 7.1000e-08 - accuracy: 0.79 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 323/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 8.4440e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.8678e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.6466e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 324/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 0s - loss: 7.5860e-08 - accuracy: 0.89 - ETA: 0s - loss: 7.8427e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.6909e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.7251e-08 - accuracy: 0.84 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 325/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 6.9849e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.7800e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.9921e-08 - accuracy: 0.80 - ETA: 0s - loss: 6.9823e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2773e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 326/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.1921e-07 - accuracy: 1.00 - ETA: 0s - loss: 9.1891e-08 - accuracy: 0.87 - ETA: 0s - loss: 8.2530e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 327/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.8763e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.3087e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3761e-08 - accuracy: 0.84 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 328/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.0248e-08 - accuracy: 0.76 - ETA: 0s - loss: 7.3678e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.4092e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 329/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 330/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1876e-08 - accuracy: 0.81 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 331/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.5290e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 332/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1194e-08 - accuracy: 0.83 - ETA: 0s - loss: 8.0094e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.7060e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 333/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.0958e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.8738e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2213e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 334/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 0s - loss: 7.1000e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.2102e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 335/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.77 - ETA: 0s - loss: 6.8711e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.1119e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1746e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.83 - 1s 12ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 336/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.5565e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5698e-08 - accuracy: 0.89 - ETA: 0s - loss: 7.2595e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 337/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.8545e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5058e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4025e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 338/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 1.00 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.6074e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5698e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.6989e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2977e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.6074e-08 - accuracy: 0.82 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 340/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 0s - loss: 6.4572e-08 - accuracy: 0.77 - ETA: 0s - loss: 7.0123e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.3974e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 341/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.9290e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.9348e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.2153e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 342/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.50 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.7699e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5698e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2700e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3844e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 343/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0248e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.82 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 344/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.7817e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.6259e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.7486e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.5038e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4114e-08 - accuracy: 0.84 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 345/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.0958e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.9397e-08 - accuracy: 0.84 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 346/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.9921e-08 - accuracy: 0.88 - ETA: 0s - loss: 6.7379e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1438e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 347/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.62 - ETA: 0s - loss: 8.8052e-08 - accuracy: 0.88 - ETA: 0s - loss: 8.6923e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.9247e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4944e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4898e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 348/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3264e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 349/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.9473e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5215e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4054e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2977e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 350/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1194e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1194e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2248e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 351/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.2916e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.8370e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1000e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3120e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 352/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.7486e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.7486e-08 - accuracy: 0.76 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 353/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0532e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.0248e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4103e-08 - accuracy: 0.81 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 354/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.5802e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.5533e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 355/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.1194e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.6764e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 356/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.5382e-08 - accuracy: 0.74 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 357/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.4572e-08 - accuracy: 0.70 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.77 - ETA: 0s - loss: 7.2450e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.1951e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2595e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 358/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.75 - ETA: 0s - loss: 7.3678e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.5802e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.81 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 359/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.5183e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1438e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 360/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.7883e-08 - accuracy: 0.84 - ETA: 0s - loss: 6.4864e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.5023e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4124e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 361/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3954e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4167e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 362/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.3330e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.7883e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2153e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.0442e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3796e-08 - accuracy: 0.83 - 1s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 363/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.5183e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5748e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2595e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 364/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.90 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2964e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3191e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 365/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.9473e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.2122e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.1687e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 366/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.50 - ETA: 0s - loss: 7.1194e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2089e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 367/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.6859e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 368/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.8545e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.85 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 369/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 8.3447e-08 - accuracy: 0.81 - ETA: 0s - loss: 8.0466e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.5652e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3603e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 370/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 8.1956e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.8763e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3654e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 371/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.7945e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2562e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4080e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 372/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.1067e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.84 - ETA: 0s - loss: 6.8120e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 373/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 5.6895e-08 - accuracy: 0.84 - ETA: 0s - loss: 6.1467e-08 - accuracy: 0.79 - ETA: 0s - loss: 6.7587e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2248e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 374/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 0s - loss: 7.6368e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2732e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 375/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.5499e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.5652e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 376/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 8.1956e-08 - accuracy: 0.89 - ETA: 0s - loss: 7.5748e-08 - accuracy: 0.89 - ETA: 0s - loss: 7.6635e-08 - accuracy: 0.90 - ETA: 0s - loss: 7.1266e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.1898e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 377/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 1s - loss: 6.7055e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.0846e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.1640e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2153e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3466e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 378/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.1369e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 379/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.8976e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4898e-08 - accuracy: 0.84 - 0s 4ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 380/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.1712e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.3910e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.7075e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 381/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.91 - ETA: 0s - loss: 7.5154e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.2102e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 382/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3329e-08 - accuracy: 0.81 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 383/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.7817e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.84 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 384/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.1467e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3796e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.6909e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4878e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 385/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.6124e-08 - accuracy: 0.76 - ETA: 0s - loss: 6.8675e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.0123e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 386/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.8918e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3654e-08 - accuracy: 0.82 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 387/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.7075e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 388/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.1667e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2977e-08 - accuracy: 0.82 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 389/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.7135e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.5251e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5570e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3388e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 390/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.9184e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.1401e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.5623e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 391/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.4572e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.4190e-08 - accuracy: 0.80 - ETA: 0s - loss: 6.4261e-08 - accuracy: 0.79 - ETA: 0s - loss: 6.6378e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2102e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1687e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3490e-08 - accuracy: 0.82 - 0s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 392/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.9765e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4142e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 393/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3954e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5623e-08 - accuracy: 0.84 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 394/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5357e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 395/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.6989e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.7135e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1640e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3678e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 396/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.37 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1369e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.0248e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1194e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3052e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 397/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.6482e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.84 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 398/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 0s - loss: 6.7733e-08 - accuracy: 0.77 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4888e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 399/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.9091e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3210e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2937e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 400/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.5570e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5003e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3828e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 401/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.5499e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4025e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3415e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 402/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.0248e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2937e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2562e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.84 - 1s 11ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.0561e-08 - accuracy: 0.80 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 404/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 2s - loss: 7.4506e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.9247e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3210e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5467e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5357e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3415e-08 - accuracy: 0.83 - 1s 12ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 405/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.50 - ETA: 0s - loss: 8.0466e-08 - accuracy: 0.77 - ETA: 0s - loss: 8.1956e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.1712e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3314e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 406/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.1733e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5127e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.6989e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3329e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3828e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 407/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.78 - ETA: 0s - loss: 6.9087e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3700e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 408/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 8.5682e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.7699e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2213e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2595e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 409/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.6798e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.5802e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3329e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 410/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.8570e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.2153e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2450e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2753e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3828e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 411/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 8.3447e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.6294e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.5334e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 412/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.9802e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.1667e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 413/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.2753e-08 - accuracy: 0.77 - ETA: 0s - loss: 7.2909e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3229e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3264e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 414/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.90 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3229e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3742e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4167e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 415/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3796e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 416/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0248e-08 - accuracy: 0.88 - ETA: 0s - loss: 6.8675e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1141e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.84 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 417/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3087e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3933e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3441e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2753e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4142e-08 - accuracy: 0.84 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 418/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.92 - ETA: 0s - loss: 8.1025e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.7486e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3329e-08 - accuracy: 0.84 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 419/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.89 - ETA: 0s - loss: 7.5748e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5499e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 420/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.7486e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.6798e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.8479e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.9367e-08 - accuracy: 0.86 - ETA: 0s - loss: 6.9953e-08 - accuracy: 0.85 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 421/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.50 - ETA: 0s - loss: 6.4075e-08 - accuracy: 0.86 - ETA: 0s - loss: 6.9016e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4114e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 422/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1194e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5102e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.3796e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 423/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.1194e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.0494e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.0395e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4861e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 424/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.2798e-08 - accuracy: 0.86 - ETA: 0s - loss: 6.4572e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.2178e-08 - accuracy: 0.85 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 425/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.62 - ETA: 0s - loss: 6.8775e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.1797e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2022e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.6034e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 426/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.50 - ETA: 0s - loss: 7.5748e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3885e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.0674e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 427/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 0s - loss: 7.8976e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3828e-08 - accuracy: 0.82 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 428/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.9016e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.2595e-08 - accuracy: 0.82 - 0s 4ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 429/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.7410e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1876e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2271e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 430/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.3264e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5215e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.5698e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.3109e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 431/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 0s - loss: 7.7486e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5748e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4142e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 432/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.6227e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2519e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.0958e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3402e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2153e-08 - accuracy: 0.81 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 433/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.2519e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3678e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5925e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.5409e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3796e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 434/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 435/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.8675e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1608e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2773e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 436/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.62 - ETA: 0s - loss: 7.9473e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.7817e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 437/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.1733e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.7733e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.6617e-08 - accuracy: 0.84 - ETA: 0s - loss: 6.5436e-08 - accuracy: 0.84 - ETA: 0s - loss: 6.8545e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.0674e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 438/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.8297e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.4572e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1951e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 439/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3064e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2732e-08 - accuracy: 0.84 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 440/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.78 - ETA: 0s - loss: 6.9087e-08 - accuracy: 0.79 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.5020e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5270e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 441/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 8.0466e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.8054e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.7251e-08 - accuracy: 0.84 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 442/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 8.0466e-08 - accuracy: 0.91 - ETA: 0s - loss: 7.6259e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.3210e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1438e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 443/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.2088e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.4572e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.8987e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.82 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 444/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.5382e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.3109e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3120e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 445/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.8763e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3574e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.6989e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5215e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2122e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2213e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4054e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2153e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 1s 15ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 446/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 1.00 - ETA: 0s - loss: 7.9473e-08 - accuracy: 0.91 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.89 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.6209e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3120e-08 - accuracy: 0.84 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 447/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.1712e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5003e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5251e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 448/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.9924e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.6859e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4971e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 449/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 8.6214e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.8103e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3828e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 450/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3828e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.5382e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 451/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.2643e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2519e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.0532e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.1831e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 452/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.8918e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4009e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.85 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 453/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.2088e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.4310e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.7587e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.0248e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3844e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 454/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.1921e-07 - accuracy: 1.00 - ETA: 0s - loss: 8.0715e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.5290e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 455/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.6559e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4142e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 456/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.83 - ETA: 0s - loss: 6.7055e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.3574e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.1831e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 457/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.50 - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.79 - ETA: 0s - loss: 6.9849e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.1667e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.3722e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 458/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.62 - ETA: 0s - loss: 8.0094e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3415e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 459/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.8479e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2178e-08 - accuracy: 0.81 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 460/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.2916e-08 - accuracy: 0.77 - ETA: 0s - loss: 6.7733e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4092e-08 - accuracy: 0.82 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 461/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 1.00 - ETA: 0s - loss: 8.6923e-08 - accuracy: 0.87 - ETA: 0s - loss: 8.0577e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 462/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.3151e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2937e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.1345e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 463/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.9924e-08 - accuracy: 0.89 - ETA: 0s - loss: 7.3910e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.2089e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 464/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.1067e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.2753e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3544e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.1962e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.50 - ETA: 0s - loss: 7.8570e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3954e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3796e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 466/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.9802e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2298e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3828e-08 - accuracy: 0.84 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 467/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.75 - ETA: 0s - loss: 7.8889e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.6890e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3603e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2732e-08 - accuracy: 0.82 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 468/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2753e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.5003e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2377e-08 - accuracy: 0.84 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 469/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.7817e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5251e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.4009e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4878e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3813e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3844e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 470/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.6047e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.5821e-08 - accuracy: 0.85 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 471/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 0s - loss: 7.6259e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3109e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.82 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 472/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 8.3447e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.6798e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.5925e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3478e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 473/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.62 - ETA: 0s - loss: 6.5879e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2492e-08 - accuracy: 0.82 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 474/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.8232e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2595e-08 - accuracy: 0.83 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 475/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.1000e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.0660e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 476/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.5996e-08 - accuracy: 0.85 - ETA: 0s - loss: 6.8711e-08 - accuracy: 0.81 - ETA: 0s - loss: 6.8410e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2583e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4142e-08 - accuracy: 0.84 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 477/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.62 - ETA: 0s - loss: 6.6663e-08 - accuracy: 0.78 - ETA: 0s - loss: 7.1951e-08 - accuracy: 0.81 - 0s 4ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 478/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.8479e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.6741e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.2583e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2977e-08 - accuracy: 0.84 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 479/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 6.3330e-08 - accuracy: 0.79 - ETA: 0s - loss: 6.9348e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3191e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 480/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1526e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3466e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 481/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.3629e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2102e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2803e-08 - accuracy: 0.81 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 482/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.0781e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.5102e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.6209e-08 - accuracy: 0.84 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 483/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.80 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.1876e-08 - accuracy: 0.79 - ETA: 0s - loss: 7.1029e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 484/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.6989e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.7486e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.5079e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.81 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 485/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.9473e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.2213e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.2436e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 486/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.6798e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.5334e-08 - accuracy: 0.88 - ETA: 0s - loss: 7.5102e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4909e-08 - accuracy: 0.83 - 1s 12ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.50 - ETA: 0s - loss: 6.5565e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.3669e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.8370e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.0619e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3064e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3813e-08 - accuracy: 0.83 - 0s 10ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 488/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.1876e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.2718e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.0478e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 489/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.6798e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3933e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3654e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3512e-08 - accuracy: 0.83 - 0s 7ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 490/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.62 - ETA: 0s - loss: 6.8711e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.0248e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.2474e-08 - accuracy: 0.82 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 491/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.5499e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.2786e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2895e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 492/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.75 - ETA: 0s - loss: 6.9539e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1797e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.6741e-08 - accuracy: 0.85 - ETA: 0s - loss: 7.4986e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.3087e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 493/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.62 - ETA: 0s - loss: 5.9605e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0248e-08 - accuracy: 0.82 - ETA: 0s - loss: 6.8297e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.2786e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4133e-08 - accuracy: 0.84 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 494/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.62 - ETA: 0s - loss: 7.7817e-08 - accuracy: 0.75 - ETA: 0s - loss: 7.2850e-08 - accuracy: 0.79 - ETA: 0s - loss: 6.9765e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.1194e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3828e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 495/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 0s - loss: 9.4995e-08 - accuracy: 0.84 - ETA: 0s - loss: 8.0466e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.8852e-08 - accuracy: 0.86 - ETA: 0s - loss: 7.5903e-08 - accuracy: 0.84 - ETA: 0s - loss: 7.4932e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 496/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.9605e-08 - accuracy: 1.00 - ETA: 0s - loss: 6.7987e-08 - accuracy: 0.84 - ETA: 0s - loss: 6.9384e-08 - accuracy: 0.84 - 0s 5ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 497/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.4703e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.0367e-08 - accuracy: 0.80 - ETA: 0s - loss: 7.5020e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.4888e-08 - accuracy: 0.83 - 0s 6ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 498/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 1.00 - ETA: 0s - loss: 7.8231e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.7945e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.9473e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.6890e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 499/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.0431e-07 - accuracy: 0.87 - ETA: 0s - loss: 7.7945e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3016e-08 - accuracy: 0.81 - ETA: 0s - loss: 7.3992e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3388e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3181e-08 - accuracy: 0.83 - 0s 8ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n",
      "Epoch 500/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 8.9407e-08 - accuracy: 0.87 - ETA: 0s - loss: 7.7699e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.6989e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4054e-08 - accuracy: 0.82 - ETA: 0s - loss: 7.3742e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.4506e-08 - accuracy: 0.83 - ETA: 0s - loss: 7.3360e-08 - accuracy: 0.83 - 0s 9ms/step - loss: 7.3360e-08 - accuracy: 0.8324 - val_loss: 7.9910e-08 - val_accuracy: 0.9011\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                         epochs=500,\n",
    "                         validation_split=0.2,\n",
    "                   batch_size= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(history.history)[['val_loss', 'loss']].plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "# plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.gca().set_xlim(0, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.335957e-08</td>\n",
       "      <td>0.782967</td>\n",
       "      <td>7.990953e-08</td>\n",
       "      <td>0.868132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.335957e-08</td>\n",
       "      <td>0.782967</td>\n",
       "      <td>7.990953e-08</td>\n",
       "      <td>0.868132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.335957e-08</td>\n",
       "      <td>0.782967</td>\n",
       "      <td>7.990953e-08</td>\n",
       "      <td>0.868132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.335957e-08</td>\n",
       "      <td>0.782967</td>\n",
       "      <td>7.990953e-08</td>\n",
       "      <td>0.868132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.335957e-08</td>\n",
       "      <td>0.782967</td>\n",
       "      <td>7.990953e-08</td>\n",
       "      <td>0.868132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>7.335957e-08</td>\n",
       "      <td>0.782967</td>\n",
       "      <td>7.990953e-08</td>\n",
       "      <td>0.868132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>7.335957e-08</td>\n",
       "      <td>0.782967</td>\n",
       "      <td>7.990953e-08</td>\n",
       "      <td>0.868132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>7.335957e-08</td>\n",
       "      <td>0.782967</td>\n",
       "      <td>7.990953e-08</td>\n",
       "      <td>0.868132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>7.335957e-08</td>\n",
       "      <td>0.782967</td>\n",
       "      <td>7.990953e-08</td>\n",
       "      <td>0.868132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>7.335957e-08</td>\n",
       "      <td>0.782967</td>\n",
       "      <td>7.990953e-08</td>\n",
       "      <td>0.868132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss  accuracy      val_loss  val_accuracy\n",
       "0    7.335957e-08  0.782967  7.990953e-08      0.868132\n",
       "1    7.335957e-08  0.782967  7.990953e-08      0.868132\n",
       "2    7.335957e-08  0.782967  7.990953e-08      0.868132\n",
       "3    7.335957e-08  0.782967  7.990953e-08      0.868132\n",
       "4    7.335957e-08  0.782967  7.990953e-08      0.868132\n",
       "..            ...       ...           ...           ...\n",
       "495  7.335957e-08  0.782967  7.990953e-08      0.868132\n",
       "496  7.335957e-08  0.782967  7.990953e-08      0.868132\n",
       "497  7.335957e-08  0.782967  7.990953e-08      0.868132\n",
       "498  7.335957e-08  0.782967  7.990953e-08      0.868132\n",
       "499  7.335957e-08  0.782967  7.990953e-08      0.868132\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - ETA: 0s - loss: 6.3330e-08 - accuracy: 0.84 - 0s 9ms/step - loss: 7.5290e-08 - accuracy: 0.8421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.529009593554292e-08, 0.8421052694320679]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((model.predict(X_test) > 0.5)*1).reshape((114,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
